# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.
INPUT_DIR = config["basecalled_dir"]
OUTPUT_DIR = config["results_dir"]
wildcard_constraints:
        barcode="^BRK"

# Allow users to fix the underlying OS via singularity.
singularity: "docker://continuumio/miniconda3"

#rule all:
#    input:
        # The first rule should define the default target files
        # Subsequent target rules can be specified below. They should start with all_*.


#include: "rules/common.smk"
#include: "rules/other.smk"
rule demultiplex:
    input: 
        INPUT_DIR + "{live_batch}.fastq"
    output: 
        temp(OUTPUT_DIR + "demultiplexed_fq/{live_batch}")
    threads: 2
    shell:
        "{config[guppy_dir]}/guppy_barcoder -i {input} -s {output}  -t {threads}  --barcode_kits SQK16S-GXO"

rule nanofilt:
    input: 
        OUTPUT_DIR + "demultiplexed_fq/{live_batch}/{barcode}" 
    output: 
        temp(OUTPUT_DIR + "filt_fq/{live_batch}/{barcode}.fastq")
    conda:
        "workflow/envs/nanofilt.yaml"
    shell: 
        """
        cat {input}/*.fastq > {input}.fastq
        cat {input}.fastq | NanoFilt -q 8 -l 1000 --maxlength 1600 --headcrop 15 --tailcrop 15 > {output}
        """

rule fq2fa:
    input: 
        OUTPUT_DIR + "filt_fq/{live_batch}/{barcode}.fastq"
    output: 
        temp(OUTPUT_DIR + "filt_fa/{live_batch}/{barcode}.fasta")
    shell: 
        """
        config[usearch11] -fastq_filter {input} -fastaout {output}
        find filt_fa/{wildcards.live_batch}/*.fasta -size -100k -delete # remove small files 0-10 reads
        """ 

rule fa_number:
    input: 
        OUTPUT_DIR + "filt_fa/{live_batch}/{barcode}.fasta"
    output: 
        temp(OUTPUT_DIR + "filt_fa/{live_batch}/adjusted-{barcode}.fasta")
    conda:
        "workflow/envs/fa_number.yaml"
    shell: 
        "fasta_number.py {input} {wildcards.barcode}_ > {output}